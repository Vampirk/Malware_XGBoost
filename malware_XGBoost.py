import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier

# CSV 파일 로드
df = pd.read_csv('pe_info.csv')

# 널값 처리: 수치형 데이터는 중앙값으로, 범주형 데이터는 'Unknown'으로 대체
for column in df.columns:
    if df[column].dtype == 'object':  # 범주형 데이터
        df[column] = df[column].fillna('Unknown')
    else:  # 수치형 데이터
        df[column] = df[column].fillna(df[column].median())

# 새로운 CSV 파일로 저장
df.to_csv('pe_info_filled.csv', index=False)

# 대체된 CSV 파일 로드
df_filled = pd.read_csv('pe_info_filled.csv')

# 특성과 레이블 분리
X = df_filled.drop(columns=['Malicious'])  # 특성
y = df_filled['Malicious']  # 레이블
# 범주형 열을 원핫 인코딩으로 변환
X_encoded = pd.get_dummies(X)

# 대괄호와 부등호가 포함된 열 이름 수정
X_encoded.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_encoded.columns]

# 학습용과 테스트용 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# XGBoost 모델과 파이프라인 설정
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # 스케일러 추가
    ('xgb', model)
])

# 하이퍼파라미터 튜닝을 위한 GridSearchCV 설정
param_grid = {
    'xgb__n_estimators': [100, 200],
    'xgb__learning_rate': [0.01, 0.1],
    'xgb__max_depth': [4, 6, 8]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

# 교차 검증을 통한 모델 평가
cv_scores = cross_val_score(best_model, X_encoded, y, cv=5)
print(f"CV Accuracy: {cv_scores.mean()} ± {cv_scores.std()}")

# 최종 모델을 사용하여 테스트 데이터로 평가
test_accuracy = best_model.score(X_test, y_test)
print("Test Accuracy:", test_accuracy)

