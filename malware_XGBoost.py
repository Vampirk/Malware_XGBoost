import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import precision_score, recall_score, f1_score
import cupy as cp
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
from sklearn.model_selection import learning_curve

def preprocess_data(file_path):
    """
    CSV 파일을 로드하고, 데이터 전처리를 수행합니다.

    Args:
        file_path (str): 전처리할 CSV 파일의 경로.

    Returns:
        cupy.ndarray: 전처리된 특성 데이터.
        cupy.ndarray: 전처리된 레이블 데이터.
    """
    df = pd.read_csv(file_path)

    # 널값 처리: 수치형 데이터는 중앙값으로, 범주형 데이터는 'Unknown'으로 대체
    for column in df.columns:
        if df[column].dtype == 'object':  # 범주형 데이터
            df[column] = df[column].fillna('Unknown')
        else:  # 수치형 데이터
            df[column] = df[column].fillna(df[column].median())

    # 특성 데이터와 레이블 데이터 분리
    X = df.drop(columns=['Malicious'])
    y = df['Malicious']

    # 입력 데이터를 부동 소수점 형식으로 변환
    X_encoded = pd.get_dummies(X)
    X_encoded = X_encoded.astype(cp.float32)

    # 입력 데이터를 CuPy 배열로 변환하고 GPU로 이동
    X_encoded_gpu = cp.asarray(X_encoded.values)
    y_gpu = cp.asarray(y.values)

    return X_encoded_gpu, y_gpu

def split_data(X, y, test_size=0.2, random_state=42):
    """
    데이터를 학습용과 테스트용으로 분할합니다.

    Args:
        X (cupy.ndarray): 특성 데이터.
        y (cupy.ndarray): 레이블 데이터.
        test_size (float, optional): 테스트 데이터 비율. 기본값은 0.2.
        random_state (int, optional): 랜덤 시드. 기본값은 42.

    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    X_train, X_test, y_train, y_test = train_test_split(X.get(), y.get(), test_size=test_size, random_state=random_state)
    X_train, X_test, y_train, y_test = cp.asarray(X_train), cp.asarray(X_test), cp.asarray(y_train), cp.asarray(y_test)
    return X_train, X_test, y_train, y_test

def train_model(X_train, y_train, X_val, y_val):
    """
    XGBoost 모델을 학습합니다.

    Args:
        X_train (cupy.ndarray): 학습용 특성 데이터.
        y_train (cupy.ndarray): 학습용 레이블 데이터.

    Returns:
        xgboost.XGBClassifier: 학습된 XGBoost 모델.
    """
    # 모델 학습
    model = XGBClassifier(use_label_encoder=False, eval_metric=['logloss', 'error', 'auc'],
                          tree_method='hist', device='cuda', early_stopping_rounds=10,
                          num_class=1, objective='binary:logistic')
    model.fit(X_train, y_train, eval_set=[(X_val, y_val)])
    return model

def evaluate_model(model, X_test, y_test):
    """
    학습된 모델을 테스트 데이터로 평가합니다.

    Args:
        model (xgboost.XGBClassifier): 학습된 XGBoost 모델.
        X_test (cupy.ndarray): 테스트용 특성 데이터.
        y_test (cupy.ndarray): 테스트용 레이블 데이터.

    Returns:
        tuple: (accuracy, precision, recall, f1)
    """
    y_pred = model.predict(X_test)
    y_test = y_test.get()

    accuracy = model.score(X_test, y_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    return accuracy, precision, recall, f1

def plot_training_history(model):
    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12))

    eval_results = model.evals_result()

    if 'validation_0' in eval_results:
        # 손실 함수 그래프
        if 'logloss' in eval_results['validation_0']:
            logloss = eval_results['validation_0']['logloss']
            epochs = range(len(logloss))
            ax1.plot(epochs, logloss, label='Validation Loss')
            ax1.set_title('Model Loss')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Log Loss')
            ax1.set_xticks(epochs)
            ax1.legend()

        # 오류율 그래프
        if 'error' in eval_results['validation_0']:
            error = eval_results['validation_0']['error']
            epochs = range(len(error))
            ax2.plot(epochs, error, label='Validation Error')
            ax2.set_title('Model Error')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Error')
            ax2.set_xticks(epochs)
            ax2.set_ylim(0, 1)
            ax2.legend()

        # AUC 그래프
        if 'auc' in eval_results['validation_0']:
            auc = eval_results['validation_0']['auc']
            epochs = range(len(auc))
            ax3.plot(epochs, auc, label='Validation AUC')
            ax3.set_title('Model AUC')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('AUC')
            ax3.set_xticks(epochs)
            ax3.set_ylim(0, 1)
            ax3.legend()

    plt.tight_layout()
    plt.savefig('training_history.png')
    plt.show()

if __name__ == "__main__":
    # 데이터 전처리
    X, y = preprocess_data('pe_info.csv')

    # 데이터 분할
    X_train, X_test, y_train, y_test = split_data(X, y)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # 모델 학습
    model = train_model(X_train, y_train, X_val, y_val)

    # 모델 평가
    accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)

    # 훈련 과정 그래프 출력 및 저장
    plot_training_history(model)

    print("Test Accuracy:", accuracy)
    print("Test Precision:", precision)
    print("Test Recall:", recall)
    print("Test F1-score:", f1)
