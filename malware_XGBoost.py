import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.metrics import precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import xgboost as xgb

def preprocess_data(file_path):
    """
    CSV 파일을 로드하고, 데이터 전처리를 수행합니다.

    Args:
        file_path (str): 전처리할 CSV 파일의 경로.

    Returns:
        pandas.DataFrame: 전처리된 데이터프레임.
    """
    df = pd.read_csv(file_path)

    # 널값 처리: 수치형 데이터는 중앙값으로, 범주형 데이터는 'Unknown'으로 대체
    for column in df.columns:
        if df[column].dtype == 'object':  # 범주형 데이터
            df[column] = df[column].fillna('Unknown')
        else:  # 수치형 데이터
            df[column] = df[column].fillna(df[column].median())

    # 새로운 CSV 파일로 저장
    df.to_csv('pe_info_filled.csv', index=False)

    return df

def split_data(X, y, test_size=0.2, random_state=42):
    """
    데이터를 학습용과 테스트용으로 분할합니다.

    Args:
        X (pandas.DataFrame): 특성 데이터.
        y (pandas.Series): 레이블 데이터.
        test_size (float, optional): 테스트 데이터 비율. 기본값은 0.2.
        random_state (int, optional): 랜덤 시드. 기본값은 42.

    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    return train_test_split(X, y, test_size=test_size, random_state=random_state)

def train_model(X_train, y_train, param_grid):
    """
    XGBoost 모델을 학습하고, 최적의 하이퍼파라미터를 찾습니다.

    Args:
        X_train (pandas.DataFrame): 학습용 특성 데이터.
        y_train (pandas.Series): 학습용 레이블 데이터.
        param_grid (dict): 탐색할 하이퍼파라미터 범위.

    Returns:
        sklearn.pipeline.Pipeline: 최적의 하이퍼파라미터로 학습된 파이프라인 모델.
    """
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('xgb', model)
    ])

    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train, y_train)

    print("Best parameters:", grid_search.best_params_)
    return grid_search.best_estimator_

def evaluate_model(best_model, X_test, y_test):
    """
    학습된 모델을 테스트 데이터로 평가합니다.

    Args:
        best_model (sklearn.pipeline.Pipeline): 학습된 파이프라인 모델.
        X_test (pandas.DataFrame): 테스트용 특성 데이터.
        y_test (pandas.Series): 테스트용 레이블 데이터.

    Returns:
        tuple: (accuracy, precision, recall, f1)
    """
    y_pred = best_model.predict(X_test)

    accuracy = best_model.score(X_test, y_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    return accuracy, precision, recall, f1

def plot_feature_importance(best_model, X, save_path):
    """
    학습된 XGBoost 모델의 특성 중요도를 시각화하고 파일로 저장합니다.

    Args:
        best_model (sklearn.pipeline.Pipeline): 학습된 파이프라인 모델.
        X (pandas.DataFrame): 특성 데이터.
        save_path (str): 특성 중요도 그래프를 저장할 경로.
    """
    feature_importance = best_model.named_steps['xgb'].feature_importances_
    feature_names = X.columns

    plt.figure(figsize=(12, 6))
    xgb.plot_importance(best_model.named_steps['xgb'], max_num_features=20, importance_type='gain', xlabel='Feature Importance')
    plt.title("Feature Importance")
    plt.savefig(save_path)

# 메인 로직
df = preprocess_data('pe_info.csv')
X = df.drop(columns=['Malicious'])
y = df['Malicious']

X_encoded = pd.get_dummies(X)
X_encoded.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_encoded.columns]

X_train, X_test, y_train, y_test = split_data(X_encoded, y)

param_grid = {
    'xgb__n_estimators': [100, 200],
    'xgb__learning_rate': [0.01, 0.1],
    'xgb__max_depth': [4, 6, 8]
}

best_model = train_model(X_train, y_train, param_grid)

cv_scores = cross_val_score(best_model, X_encoded, y, cv=5)
print(f"CV Accuracy: {cv_scores.mean()} ± {cv_scores.std()}")

accuracy, precision, recall, f1 = evaluate_model(best_model, X_test, y_test)
print("Test Accuracy:", accuracy)
print("Test Precision:", precision)
print("Test Recall:", recall)
print("Test F1-score:", f1)

plot_feature_importance(best_model, X_encoded, 'feature_importance.png')
